We now report experimental results that compare the recommendation performance of the proposed method to competing methods on a number of datasets. We used two proprietary and two publicly available dataset for evaluating all methods. In all of our dataset, we remove the users and items with less than 3 purchases.  Table \ref{tbl:datasets} summarises statistics of the datasets.

\begin{table}
	\centering
	\caption{Summary of datasets used in evaluation.}
	\label{tbl:datasets}
	
	\begin{tabular}{llll}
	\toprule
	\toprule	
	\textbf{Dataset} & $\numUsers$ & $\numItems$ & $ | \R_{\ui} > 0 | $ \\
	\toprule
	\MLens  & 69,557 & 9,309 & 2,909,119 \\
	\LastFM & 992 & 88,428 & 800,274\\
	\Guitar & 26,928 & 14,399 & 120,268 \\
	\Lowes & 264,054 & 57,214 & 1,398,332 \\
	\bottomrule
	\end{tabular}
\end{table}

\MLens. The MovieLens 10M dataset\footnote{\scriptsize \url{http://grouplens.org/datasets/movielens/}} is a standard benchmark for collaborative filtering tasks.
Following the ``Who Rated What'' KDD Cup 2007 challenge \citep{Bennett:2007}, we created a binarised version of the dataset suitable for evaluating implicit feedback methods.
From the original rating matrix $\R \in \{ 0, 1, \ldots, 5 \}^{\numUsers \times \numItems}$, we created a preference matrix $\tilde{\R}$ with $\tilde{\R}_{\ui} = \indicator{\R_{\ui} \geq 4}$.

\LastFM. The LastFM dataset\footnote{{\scriptsize \url{http://ocelma.net/MusicRecommendationDataset/index.html}}} \citep{Celma:2008} contains the play counts of $\sim$1000 users on $\sim$170,000 artists. As per \MLens, we binarised the raw play counts.

% \Guitar. is an anonymised dataset from a major online retailer for music instruments in US. This dataset consists of $\sim$27,000 users, $\sim$14,000 items and $\sim$120,000 item purchases.

% \Lowes. is an anonymised dataset from a major online retailer for home improvement and appliance stores in US. This dataset consists of $\sim$264,000 users, $\sim$57,000 items and $\sim$1 billion item purchases. 



\Lowes\ \& \Guitar \ are anonymized dataset provided by XXX\footnote{{\scriptsize anonymised for the blind review and will be revealed later}}, a major provider of third party recommendation services. \Guitar \ dataset consists of $\sim$27,000 users, $\sim$14,000 items and $\sim$120,000 item purchases. Similarity, \Lowes \ dataset consists of $\sim$264,000 users, $\sim$57,000 items and $\sim$1 billion item purchases. 

\subsection{Evaluation Protocol}
We split the datasets into random $90\%$-$10\%$ train-test set and hold out $10\%$ of the training set for hyperparamater tuning. We report the mean test split performance, along with standard errors corresponding to 95\% confidence intervals.
To evaluate the performance of the various recommenders, we report Precision@k and Recall@k for $k \in \{ 3, 5, 10, 20 \}$ (averaged across all test fold users), and mean average precision (mAP@20).


\subsection{Methods compared}

We compared the proposed method to a number of baselines:
\begin{compactitem}

	\item User- and item-based nearest neighbour (U-KNN and I-KNN), as per \S\ref{sec:knn}, using  cosine similarity and Jaccard coefficient to define the similarity matrix $\Sim$. For each dataset, we picked the best performing of the two metrics.

	\item PureSVD of \citet{Cremonesi:2010}.

	\item Weighted matrix factorisation (WRMF) as defined in (\ref{eqn:wrmf}).

	\item MF-RSVD of \citet{Tang:2013}.  We ran this method both on user and item based initialization, U-MF-RSVD  and I-MF-RSVD, as discussed in (\ref{eqn:U-MF-RSVD}) and (\ref{eqn:I-MF-RSVD}) respectively.
	\item SLIM, as per (\ref{eqn:slim}). For computational convenience, we used the SGDReg variant \citep{Levy:2013}, which is identical to SLIM  except that the nonnegativity constraint is removed. We did not evaluate SLIM with nonnegativity directly as~\citet{Levy:2013} reports superior performance to SLIM, and is considerably faster to train.
\end{compactitem}
Note that, We didn't compare against ~\citep{Sedhain:2016} due to its memory complexity on a large scale dataset. For instance, on \Lowes \ dataset LRec requires $\sim$260 GB of memory. 